from generators16.CCVAE import *
import argparse
from torchvision.utils import save_image
from utils.getModels import *
from utils.getData import *
from torch.utils.data import DataLoader

parser = argparse.ArgumentParser()
### model & feature size
parser.add_argument('--models', type=str, default='cnn') # cnn, mlp 
parser.add_argument('--output_channel', type=int, default=3) # local epochs for training generator
parser.add_argument('--img_size', type=int, default=16) # local epochs for training generator
### dataset
parser.add_argument('--dataset', type=str, default='mnist') # stl10, cifar10, svhn, mnist, emnist
parser.add_argument('--bs', type=int, default=128)
parser.add_argument('--local_bs', type=int, default=128)
parser.add_argument('--num_classes', type=int, default=10)
### VAE parameters
parser.add_argument('--latent_size', type=int, default=16) # local epochs for training generator

parser.add_argument('--device_id', type=str, default='0')


args = parser.parse_args()
args.device = 'cuda:' + args.device_id

gennet = CCVAE(args).to(args.device)
gennet.load_state_dict(torch.load('checkpoint/FedCVAEF.pt'))
gennet.eval()

with torch.no_grad():
    images, labels = gennet.sample_image(args) # images.shape (bs, feature^2)
    
print(images.shape) # (local_bs, output_channel, img_size, img_size)


local_models, common_net = getModel(args)
w_comm = torch.load('checkpoint/Fed_cnn_common_net.pt') # common_net = FE_MLP.to(args.device)

common_net.load_state_dict(w_comm) # feature extractor
dataset_train, dataset_test = getDataset(args)

for batch_idx, (images, labels) in enumerate(self.ldr_train):
    images = images.to(self.args.device) # images.shape: torch.Size([batch_size, 1, 28, 28])
    images = common_net(images) # x.view(-1, self.feature_size*self.feature_size) in CVAE.forward 



# ldr_train = DataLoader(dataset_train, batch_size=args.bs, shuffle=True)
# optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=args.momentum, weight_decay=args.weight_decay)
# epoch_loss = []

# for iter in range(1,args.n_epochs+1): # train by samples generated by generator
#     net.train()
#     batch_loss = []

#     for batch_idx, (images, labels) in enumerate(ldr_train):
#         images, labels = images.to(args.device), labels.to(args.device)
#         images = common_net(images) # real features
        
#         net.zero_grad()
#         logits, log_probs = net(images)
#         loss = F.cross_entropy(logits, labels) # net.fc1.weight.grad / net.fc5.weight.grad
#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()

#         batch_loss.append(loss.item())
#     epoch_loss.append(sum(batch_loss)/len(batch_loss))
#     print(iter, 'Epoch loss: {:.4f}'.format(epoch_loss[-1]))
