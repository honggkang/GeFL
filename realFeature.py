'''
Train the classifier network by
samples generated by feature generator
'''
from torchvision.utils import save_image

import argparse
import torch.nn as nn
from torch.utils.data import DataLoader

from modelsMNIST.GAN import *
from modelsMNIST.VAE import *
from modelsMNIST.DDPM import *

from generators16.DCGAN import *
from generators16.CCVAE import *
from mlp_generators.GAN import *
# from mainNetModels.cnn import *
from mainNetModels.cnn_sameSize import *
from mainNetModels.mlp2 import *

from utils.util import test_img
from utils.getData import *
import copy

import wandb

parser = argparse.ArgumentParser()
parser.add_argument("--n_fepochs", type=int, default=30, help="number of epochs of training by generated samples")
parser.add_argument("--n_epochs", type=int, default=50, help="number of epochs of training by local samples")
parser.add_argument("--batch_size", type=int, default=32, help="size of the batches")
parser.add_argument("--bs", type=int, default=128, help="size of the batches")
parser.add_argument('--local_bs', type=int, default=128)

parser.add_argument('--device_id', type=str, default='0')

parser.add_argument('--dataset', type=str, default='mnist') # stl10, cifar10, svhn, mnist
parser.add_argument('--models', type=str, default='mlp') # cnn2, cnn, mlp
parser.add_argument("--num_classes", type=int, default=10, help="number of classes for dataset")

parser.add_argument("--img_size", type=int, default=28, help="size of each image dimension")
parser.add_argument("--output_channel", type=int, default=1, help="number of image channels")

parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")

### generators
parser.add_argument('--gen', type=str, default='dcgan') # dcgan, cave, gan, vae, ddpm
parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space") # GAN
parser.add_argument("--latent_size", type=int, default=20, help="dimensionality of the latent space") # VAE
parser.add_argument("--n_feat", type=int, default=128) # DDPM
parser.add_argument("--n_T", type=int, default=5) # DDPM
### optimizer
parser.add_argument('--momentum', type=float, default=0)
parser.add_argument('--weight_decay', type=float, default=0)
### logging
parser.add_argument('--name', type=str, default='default') # dcgan, vae, ddpm
parser.add_argument('--wandb', type=bool, default=False)
### experminets
parser.add_argument('--rs', type=int, default=0)
parser.add_argument("--sample_interval", type=int, default=20, help="interval between image sampling")

args = parser.parse_args()
args.device = 'cuda:' + args.device_id
args.img_shape = (args.output_channel, args.img_size, args.img_size)

torch.manual_seed(args.rs)
torch.cuda.manual_seed(args.rs)
np.random.seed(args.rs)
random.seed(args.rs)

lr = 1e-1 # MLP

if args.models == 'mlp':
    common_net = FE_MLP().to(args.device)
    net = MLP3().to(args.device)
    w_comm = torch.load('models/save/Fed_mlp2_common_net_sameSize.pt') # common_net = FE_MLP.to(args.device)
elif 'cnn' in args.models:
    common_net = FE_CNN().to(args.device)
    w_comm = torch.load('models/save/Fed_cnn2_common_net_sameSize.pt') # common_net = FE_MLP.to(args.device)

common_net.load_state_dict(w_comm)
common_net.eval()
dataset_train, dataset_test = getDataset(args)

batch_iter = len(dataset_train)//args.batch_size # MNIST
sample_num = 100
ldr_train = DataLoader(dataset_train, batch_size=100, shuffle=True, drop_last=True)

with torch.no_grad():
    for batch_idx, (images, labels) in enumerate(ldr_train):
        images = images.to(args.device)
        f_images = common_net(images)
        save_image(f_images.view(sample_num, args.output_channel, args.img_size, args.img_size), 
                    'imgFedGANF/' + 'RawFeat_' + str(batch_idx) + '.png', nrow=10)
        # save_image(images.view(sample_num, args.output_channel, args.img_size, args.img_size), 
        #             'imgFedDCGAN/' + 'RawSample_' + str(batch_idx) + '.png', nrow=10)
        print(batch_idx)
        if batch_idx == 10:
            break