'''
Train feature network to extract feature images
'''
import argparse
import torch.nn as nn
from torch.utils.data import DataLoader
import copy

from utils.localUpdate import *
from utils.getData import *
from utils.average import *
from utils.util import test_img
from FeatureExtractor.mlp import *
from mainNetModels.cnn import *

parser = argparse.ArgumentParser()
# parser.add_argument('--num_users', type=int, default=100)
parser.add_argument('--noniid', action='store_true') # default: false
parser.add_argument('--dir_param', type=float, default=0.3)

parser.add_argument('--bs', type=int, default=32)
parser.add_argument("--batch_size", type=int, default=32, help="size of the batches")

parser.add_argument('--local_bs', type=int, default=32)
parser.add_argument('--momentum', type=float, default=0)
parser.add_argument('--local_ep', type=int, default=5)

parser.add_argument('--weight_decay', type=float, default=0)
parser.add_argument('--num_classes', type=int, default=10)

parser.add_argument('--num_experiment', type=int, default=3, help="the number of experiments")
parser.add_argument('--device_id', type=str, default='0')
parser.add_argument('--wandb', type=bool, default=False)

parser.add_argument('--dataset', type=str, default='mnist') # stl10, cifar10, svhn, mnist
parser.add_argument('--models', type=str, default='cnn') # cnn, mlp

parser.add_argument('--name', type=str, default='under_dev') # L-A: bad character
parser.add_argument("--n_epochs", type=int, default=100, help="number of epochs of training")

parser.add_argument('--rs', type=int, default=2, help='random seed')
parser.add_argument('--num_users', type=int, default=10)
parser.add_argument('--partial_data', type=float, default=0.1)
args = parser.parse_args()
args.device = 'cuda:' + args.device_id

if args.models == 'mlp':
    common_net = FE_MLP().to(args.device)
    net = MLP3().to(args.device)
elif args.models == 'cnn':
    common_net = FE_CNN().to(args.device)
    net = CNN3().to(args.device)

loss_func = nn.CrossEntropyLoss()
dataset_train, dataset_test = getDataset(args)
dict_users = cifar_iid(dataset_train, int(args.num_users/args.partial_data), args.rs)
lr = 1e-1

best_perf = 0
ws_glob = net.state_dict()

for iter in range(1, args.n_epochs+1): # train by samples generated by generator
    ws_local = []
    loss_locals = []
    net.load_state_dict(ws_glob)

    m = max(int(args.num_users), 1)
    idxs_users = np.random.choice(range(args.num_users), m, replace=False)
    
    for idx in idxs_users:                        
        local = LocalUpdate(args, dataset=dataset_train, idxs=dict_users[idx])
        weight, loss, _ = local.train(net=copy.deepcopy(net).to(args.device), learning_rate=lr)

        ws_local.append(weight)
        loss_locals.append(loss)
    
    ws_glob = FedAvg(ws_local)
    loss_avg = sum(loss_locals) / len(loss_locals)
    print('Round {:3d}, Avg loss {:.3f}'.format(iter, loss_avg))
    
    if iter % 10 == 0 or iter == args.n_epochs:
        net.eval()
        acc_test, loss_test = test_img(copy.deepcopy(net), dataset_test, args)
        # if acc_test > best_perf:
        #     best_perf = float(acc_test)
        print("Testing accuracy " + str(iter) + ": {:.2f}".format(acc_test))
        # if args.wandb:
        #     wandb.log({
        #         "Communication round": iter,
        #         "Local model " + str(i) + " test accuracy": acc_test
        #     })

print("Best acc:{:.2f}".format(best_perf))
w_comm = common_net.state_dict()
w = net.state_dict()

for key in w_comm:
    w_comm[key] = w[key]

torch.save(w_comm, 'models/save/' + str(args.num_users) + '_'
            + str(args.n_epochs) + 'FE_CNN.pt')